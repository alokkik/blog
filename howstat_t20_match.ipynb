{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "c150ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3, os\n",
    "import pandas as pd\n",
    "http = urllib3.PoolManager()\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Twenty20Data:\n",
    "    def __init__(self):\n",
    "        self.path = r\"C:\\Users\\Alok\\Downloads\\dataset\\cricket\"\n",
    "        self.url = \"http://howstat.com/cricket/Statistics/Matches/MatchList_T20.asp?Group=%s&v=M&Range=%s\"\n",
    "        self.date_range = [(\"2005010120051231\",\"2005\"), (\"2006010120061231\",\"2006\"), (\"2007010120071231\",\"2007\"),\\\n",
    "                          (\"2008010120081231\",\"2008\"), (\"2009010120091231\",\"2009\"), (\"2010010120101231\",\"2010\"),\\\n",
    "                          (\"2011010120111231\",\"2011\"), (\"2012010120121231\",\"2012\"), (\"2013010120131231\",\"2013\"),\\\n",
    "                          (\"2014010120141231\",\"2014\"), (\"2015010120151231\",\"2015\"), (\"2016010120161231\",\"2016\"),\\\n",
    "                          (\"2017010120171231\",\"2017\"), (\"2018010120181231\",\"2018\"), (\"2019010120191231\",\"2019\"),\\\n",
    "                          (\"2020010120201231\",\"2020\"), (\"2021010120211231\",\"2021\")]\n",
    "\n",
    "    def get_year_wise_data(self):\n",
    "        for item in self.date_range[:]:\n",
    "            print(\"Scraping data for year %s !!\"%item[1])\n",
    "            response = http.request('GET', self.url%(item[0],item[1]))\n",
    "            soup = BeautifulSoup(response.data.decode('utf-8'), \"lxml\")\n",
    "            table = soup.find(\"table\", {\"class\": \"TableLined\"})\n",
    "            df = self.extract(table)\n",
    "            df.to_csv(os.path.join(self.path,\"T20_Data_%s.csv\"%(item[1])),index=None)\n",
    "        print(\"Data saved to given path!\")\n",
    "        return\n",
    "    \n",
    "    def find_value_column(self, row):\n",
    "        if row.team1 in row.result:\n",
    "            return row.team1 \n",
    "        elif row.team2 in row.result:\n",
    "            return row.team2\n",
    "        else: return \"draw\"\n",
    "    \n",
    "    def get_teams(self, row):\n",
    "        print([item.strip() for item in row.countries.split(\"v.\")])\n",
    "        return [item.strip() for item in row.countries.split(\"v.\")]\n",
    "    \n",
    "    def preprocess_df(self, df):\n",
    "        df[['team1','team2']] = df.countries.str.split(\" v. \",expand=True)\n",
    "        #df[['team1','team2']] = df.apply(lambda row : self.get_teams(row), axis=1)\n",
    "        df['winner'] = df.apply(lambda row : self.find_value_column(row), axis=1)\n",
    "        df = df.drop([\"Serial\",\"&nbsp\",\"ground\"],axis=1)\n",
    "        return df\n",
    "    \n",
    "    def extract(self, table):\n",
    "        data = []\n",
    "        for row in table.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            cols = [ele.text.strip().lower() for ele in cols]\n",
    "            data.append([ele for ele in cols if ele])\n",
    "        df = pd.DataFrame(data[1:], columns=[\"Serial\"]+data[0])\n",
    "        df = self.preprocess_df(df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "63b3aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t20 = Twenty20Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "1f7dec08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for year 2005 !!\n",
      "Scraping data for year 2006 !!\n",
      "Scraping data for year 2007 !!\n",
      "Scraping data for year 2008 !!\n",
      "Scraping data for year 2009 !!\n",
      "Scraping data for year 2010 !!\n",
      "Scraping data for year 2011 !!\n",
      "Scraping data for year 2012 !!\n",
      "Scraping data for year 2013 !!\n",
      "Scraping data for year 2014 !!\n",
      "Scraping data for year 2015 !!\n",
      "Scraping data for year 2016 !!\n",
      "Scraping data for year 2017 !!\n",
      "Scraping data for year 2018 !!\n",
      "Scraping data for year 2019 !!\n",
      "Scraping data for year 2020 !!\n",
      "Scraping data for year 2021 !!\n",
      "Data saved to given path!\n"
     ]
    }
   ],
   "source": [
    "t20.get_year_wise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c600394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
